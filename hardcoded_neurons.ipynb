{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTM SDR Scalar Encoder\n",
    "# Input: Scalar\n",
    "# Parameters: n - number of units, w - bits used to represent signal (width), b - buckets (i.e. resolution), \n",
    "#             min - minimum value of input (inclusive), max - maximum input value (inclusive)\n",
    "class scalar_sdr:\n",
    "    \n",
    "    def __init__(self, b, w, min_, max_, shape=(1,1), neg=True):\n",
    "        if type(b) != int or type(w) != int or type(min_) != float or type(max_) != float:\n",
    "            raise TypeError(\"b - buckets must be int, w - width must be int, min_ must be float and max_ must be float\")\n",
    "        self.b = b # must be int\n",
    "        self.w = w # must be int\n",
    "        self.min = min_ # must be float\n",
    "        self.max = max_ # must be float\n",
    "        self.n = b+w-1 # number of units for encoding\n",
    "        self.ndarray_shape = shape\n",
    "        self.nodes = self.n*reduce(lambda x, y: x*y, self.ndarray_shape)\n",
    "        self.neg = neg\n",
    "        \n",
    "    def encode(self,input_):\n",
    "        if input_ > self.max or input_ < self.min:\n",
    "            raise ValueError(\"Input outside encoder range!\")\n",
    "        if type(input_) != float:\n",
    "            raise TypeError(\"Input must be float!\")\n",
    "        if self.neg:\n",
    "            output = np.zeros(self.n)-1\n",
    "        else:\n",
    "            output = np.zeros(self.n)\n",
    "        index = int((input_-self.min)/(self.max-self.min)*self.b)\n",
    "        output[index:index+self.w] = 1\n",
    "        return output\n",
    "    \n",
    "    def encode_ndarray(self,input_):\n",
    "        if input_.shape != self.ndarray_shape:\n",
    "            raise ValueError(\"Input dimensions do not match specified encoder dimensions!\")\n",
    "        output = []\n",
    "        for i in np.nditer(input_, order='K'):\n",
    "            output.append(self.encode(float(i)))\n",
    "        return np.array(output)\n",
    "    '''\n",
    "    def decode(self,input_):\n",
    "        if len(input_) != self.n: # or len(np.nonzero(input_+1)[0]) != self.w: <-- Can't have since the network is not guaranteed to produce this by any means!!!\n",
    "            raise TypeError(\"Input does not correspond to encoder encoded data!\")\n",
    "        # output = np.nonzero(input_+1)[0][0]/float(self.b)*(self.max-self.min)+self.min <-- This doesn't work really since bits can randomly fire, taking the average is a more reasonable decoding\n",
    "        median = np.median(np.nonzero(input_+1)[0])            \n",
    "        try:\n",
    "            output = int(median-float(self.w)/2.0)/float(self.b)*(self.max-self.min)+self.min # i.e. figure out center (median more outlier resistant than mean) and subtract width/2\n",
    "        except ValueError:\n",
    "            output = None\n",
    "        return output\n",
    "    '''\n",
    "    def decode(self,input_):\n",
    "        if len(input_) != self.n: \n",
    "            raise TypeError(\"Input length does not match encoder length!\")\n",
    "        if len(np.nonzero(input_+1)[0]) == 0:\n",
    "            return np.nan\n",
    "        max_ = 0\n",
    "        output = 0.0\n",
    "        for i in range(self.b):\n",
    "            x = np.zeros(self.n)-1\n",
    "            x[i:i+self.w] = 1\n",
    "            if x.shape != input_.shape:\n",
    "                input_ = input_.reshape(x.shape)\n",
    "            score = np.inner(x,input_) # this was broken for some input formats \n",
    "            if score > max_:\n",
    "                max_ = score\n",
    "                output = float(i)/float(self.b)*(self.max-self.min)+self.min\n",
    "        return output\n",
    "            \n",
    "    def decode_ndarray(self,input_):\n",
    "        if input_.shape != (reduce(lambda x, y: x*y, self.ndarray_shape)*self.n,): \n",
    "            raise ValueError(\"Input dimensions do not match specified encoder dimensions!\")\n",
    "        input_ = input_.reshape(self.ndarray_shape+(self.n,))\n",
    "        output = []\n",
    "        for i in np.ndindex(self.ndarray_shape):\n",
    "            output.append(self.decode(input_[i]))\n",
    "        output = np.array(output).reshape(self.ndarray_shape)\n",
    "        return output\n",
    "    \n",
    "    def set_ndarray_shape(self,shape):\n",
    "        if type(shape) != tuple:\n",
    "            raise TypeError(\"Must provide tuple of array dimensions!\")\n",
    "        self.ndarray_shape = shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavior data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb = pickle.load(open(\"/home/markus/dep/dep_data/bases/fb.pickle\",\"rb\"))\n",
    "fs = pickle.load(open(\"/home/markus/dep/dep_data/bases/fs.pickle\",\"rb\"))\n",
    "sd = pickle.load(open(\"/home/markus/dep/dep_data/bases/sd.pickle\", \"rb\"))\n",
    "\n",
    "bases = {\"fb\": fb, \"fs\": fs, \"sd\": sd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard coded neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_motors = [1,3,4,5,10,12]\n",
    "ts = {'fb': 124, 'fs': 126, 'sd': 117}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_encoder = scalar_sdr(30,1,-100000.0,100000.0,neg=False)\n",
    "vel_encoder = scalar_sdr(10,1,-70.0,70.0,neg=False)\n",
    "weights = []\n",
    "weights_vel = []\n",
    "for i in active_motors:\n",
    "    w = np.zeros(pos_encoder.nodes)\n",
    "    w_vel = np.array([np.zeros(vel_encoder.nodes)-1 for j in range(pos_encoder.nodes)])\n",
    "    for id_ in bases:\n",
    "        val = bases[id_][0][ts[id_]][i]\n",
    "        index_pos = int((val-pos_encoder.min)/(pos_encoder.max-pos_encoder.min)*pos_encoder.b)\n",
    "        w[index_pos] = 1\n",
    "\n",
    "        val = bases[id_][1][ts[id_]][i]\n",
    "        index_vel = int((val-vel_encoder.min)/(vel_encoder.max-vel_encoder.min)*vel_encoder.b)\n",
    "        w_vel[index_pos][index_vel] = 0\n",
    "        \n",
    "    weights.append(w)\n",
    "    weights_vel.append(w_vel)\n",
    "weights = np.array(weights)\n",
    "weights_vel = np.array(weights_vel)\n",
    "weights = weights.reshape(6,30,1)\n",
    "weights_vel = weights_vel.reshape(6,30,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_encoder = scalar_sdr(30,1,-100000.0,100000.0,shape=(6,1),neg=False)\n",
    "vel_encoder = scalar_sdr(10,1,-70.0,70.0,shape=(6,1),neg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testTrigger(id_,index):\n",
    "    #index = ts[id_]\n",
    "    pos_ = pos_encoder.encode_ndarray(bases[id_][0][index][active_motors].reshape(6,1)).reshape(6,30,1)\n",
    "    vel_ = vel_encoder.encode_ndarray(bases[id_][1][index][active_motors].reshape(6,1)).reshape(6,10,1)\n",
    "    \n",
    "    with tf.name_scope(\"input\"):\n",
    "        pos_nodes = tf.placeholder(tf.float32, [6,30,1], name=\"encoded_motor_positions\")\n",
    "        vel_nodes = tf.placeholder(tf.float32, [6,10,1], name=\"encoded_motor_velocities\")\n",
    "        trigger_bias = tf.constant(1., shape=[6,1], dtype=tf.float32)\n",
    "\n",
    "    with tf.name_scope(\"weights\"):\n",
    "        w_pos = tf.Variable(np.zeros((6,30,1)), name=\"position_weights\", dtype=tf.float32)\n",
    "        w_vel = tf.Variable(np.zeros((6,30,10)), name=\"velocity_weights\", dtype=tf.float32)\n",
    "        w_trig = tf.constant(-(6.-1e-6)/6., shape=[6,1], name=\"trigger_weights\", dtype=tf.float32)\n",
    "\n",
    "    with tf.name_scope(\"trigger\"):\n",
    "        pos_sum = tf.multiply(pos_nodes,w_pos)\n",
    "        vel_sum = tf.matmul(w_vel,vel_nodes)\n",
    "        motor_sum = pos_sum + vel_sum\n",
    "        motor_activation = tf.nn.relu(tf.sign(motor_sum))\n",
    "        trigger_sum_0 = tf.reduce_sum(motor_activation, axis = 1)\n",
    "        trigger_sum_1 = tf.reduce_sum(trigger_sum_0 + tf.multiply(trigger_bias,w_trig))\n",
    "        trigger_activation = tf.nn.relu(tf.sign(trigger_sum_1))\n",
    "\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    return sess.run(trigger_activation,{pos_nodes: pos_, w_pos: weights, vel_nodes: vel_, w_vel: weights_vel})\n",
    "    # Create a summary writer, add the 'graph' to the event file.\n",
    "    # writer = tf.summary.FileWriter(\"tf_logs\", sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "trigger = {}\n",
    "for base in bases:\n",
    "    trigger[base] = np.zeros(bases[base][0].shape[0])\n",
    "    for i in range(bases[base][0].shape[0]):\n",
    "        print i\n",
    "        trigger[base][i] = testTrigger(base,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fb': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.]),\n",
       " 'fs': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.]),\n",
       " 'sd': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         1.,  1.,  0.,  0.,  0.])}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
