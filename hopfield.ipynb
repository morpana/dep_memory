{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hopfield Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation for asynchronous Hopfield neural network\n",
    "# Note: memory capacity â‰ƒ 0.14*nodes\n",
    "class Hopfield_Neural_Network:\n",
    "    def __init__(self,nodes,iterations=100,weights=None):\n",
    "        self.nodes = nodes\n",
    "        self.iterations = iterations\n",
    "        try:\n",
    "            if weights == None:\n",
    "                self.weights = np.zeros((nodes,nodes))\n",
    "        except ValueError:\n",
    "            self.weights = weights\n",
    "    \n",
    "    def store(self,input):\n",
    "        dW = np.outer(input.transpose(),input)\n",
    "        np.fill_diagonal(dW,0)\n",
    "        self.weights += dW\n",
    "        \n",
    "    def recall(self,input):\n",
    "        update_sequence = np.random.choice(self.nodes, self.iterations)\n",
    "        for node in update_sequence:\n",
    "            input[node] = np.sign(np.inner(input,self.weights[:,node]))\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnn = Hopfield_Neural_Network(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class matrix_expansion:\n",
    "    \n",
    "    def __init__(self,active_motors):\n",
    "        self.active_motors = active_motors\n",
    "        active_sensors = np.array(active_motors*2)\n",
    "        active_sensors[len(active_motors):] += 14\n",
    "        self.active_sensors = active_sensors\n",
    "        self.shape = ()\n",
    "        \n",
    "    def load_from_file(self,filename):\n",
    "        f = open(filename,\"r\")\n",
    "        matrix = f.read()\n",
    "        f.close()\n",
    "        matrix = re.split(\",NEW_ROW,\",matrix)\n",
    "        matrix.pop()\n",
    "        matrix = np.array([np.array(re.split(\",\", row)).astype(np.float) for row in matrix])\n",
    "        self.shape = matrix.shape\n",
    "        return matrix\n",
    "        \n",
    "    def reduced_matrix(self,matrix):\n",
    "        matrix = matrix[:,self.active_sensors][self.active_motors]\n",
    "        return matrix\n",
    "    \n",
    "    def expanded_matrix(self,reduced_matrix):\n",
    "        matrix = np.zeros(self.shape)\n",
    "        flat = reduced_matrix.flatten()\n",
    "        matrix = np.zeros((14,28))\n",
    "        k = 0\n",
    "        for i in active_motors:\n",
    "            for j in active_sensors:\n",
    "                matrix[i,j] = flat[k]\n",
    "                k += 1\n",
    "        return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_motors = [1,3,4,5,10,12]\n",
    "expander = matrix_expansion(active_motors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Front back\n",
    "filename = \"/home/markus/dep/dep_matrices/front_back.dep\"\n",
    "fb_matrix = expander.load_from_file(filename)\n",
    "fb_reduced = expander.reduced_matrix(fb_matrix)\n",
    "#fb_expanded = expander.expanded_matrix(fb_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Front side\n",
    "filename = \"/home/markus/dep/dep_matrices/front_side.dep\"\n",
    "fs_matrix = expander.load_from_file(filename)\n",
    "fs_reduced = expander.reduced_matrix(fs_matrix)\n",
    "#fs_expanded = expander.expanded_matrix(fs_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side down\n",
    "filename = \"/home/markus/dep/dep_matrices/side_down.dep\"\n",
    "sd_matrix = expander.load_from_file(filename)\n",
    "sd_reduced = expander.reduced_matrix(sd_matrix)\n",
    "#sd_expanded = expander.expanded_matrix(sd_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = {\"fb\": fb_reduced, \"fs\": fs_reduced, \"sd\": sd_reduced}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors = [\"fb\",\"fs\",\"sd\"]\n",
    "transitions = {(\"fb\",\"fs\"): [], (\"fb\",\"sd\"): [], (\"fs\",\"fb\"): [], (\"fs\",\"sd\"): [], (\"sd\",\"fb\"): [], (\"sd\",\"fb\"): []}\n",
    "transition_muscle_2 = [[-1.5,-1.5,-1.5,-1.5,-1.5,-1.5],[1,1,1,1,1,1]] # [pos,...],[direction,..] -- direction = 1 -> up, direction = 0 -> down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to get positions and velocities for fb, fs and sd at -1.5 going up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb = pickle.load(open(\"/home/markus/dep/dep_data/bases/fb.pickle\",\"rb\"))\n",
    "fs = pickle.load(open(\"/home/markus/dep/dep_data/bases/fs.pickle\",\"rb\"))\n",
    "sd = pickle.load(open(\"/home/markus/dep/dep_data/bases/sd.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtained from plot, time indices that meat transition_muscle_2 condition\n",
    "fb_t = 124\n",
    "fs_t = 126\n",
    "sd_t = 117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos data\n",
    "pos = {\"fb\": fb[0][fb_t][active_motors], \"fs\": fs[0][fs_t][active_motors], \"sd\": sd[0][sd_t][active_motors]}\n",
    "# vel data\n",
    "vel = {\"fb\": fb[1][fb_t][active_motors], \"fs\": fs[1][fs_t][active_motors], \"sd\": sd[1][sd_t][active_motors]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"fb\" = [0.0,0.33], \"fs\" = [0.33, 0.66], \"sd\" = [0.66,1.00]\n",
    "brain_id = {\"fb\": 1.0/6.0, \"fs\": 0.5, \"sd\": 5.0/6.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTM SDR Scalar Encoder\n",
    "# Input: Scalar\n",
    "# Parameters: n - number of units, w - bits used to represent signal (width), b - buckets (i.e. resolution), \n",
    "#             min - minimum value of input (inclusive), max - maximum input value (inclusive)\n",
    "class scalar_sdr:\n",
    "    \n",
    "    def __init__(self, b, w, min_, max_, shape=0):\n",
    "        if type(b) != int or type(w) != int or type(min_) != float or type(max_) != float:\n",
    "            raise TypeError(\"b - buckets must be int, w - width must be int, min_ must be float and max_ must be float\")\n",
    "        self.b = b # must be int\n",
    "        self.w = w # must be int\n",
    "        self.min = min_ # must be float\n",
    "        self.max = max_ # must be float\n",
    "        self.n = b+w-1 # number of units for encoding\n",
    "        self.ndarray_shape = shape\n",
    "        \n",
    "    def encode(self,input_):\n",
    "        if input_ > self.max or input_ < self.min:\n",
    "            raise ValueError(\"Input outside encoder range!\")\n",
    "        if type(input_) != float:\n",
    "            raise TypeError(\"Input must be float!\")\n",
    "        output = np.zeros(self.n)-1\n",
    "        index = int((input_-self.min)/(self.max-self.min)*self.b)\n",
    "        output[index:index+self.w] = 1\n",
    "        return output\n",
    "    \n",
    "    def encode_ndarray(self,input_):\n",
    "        if input_.shape != self.ndarray_shape:\n",
    "            raise ValueError(\"Input dimensions do not match specified encoder dimensions!\")\n",
    "        output = []\n",
    "        for i in np.nditer(input_, order='K'):\n",
    "            output.append(self.encode(float(i)))\n",
    "        return np.array(output)\n",
    "\n",
    "    def decode(self,input_):\n",
    "        if len(input_) != self.n or len(np.nonzero(input_+1)[0]) != self.w:\n",
    "            raise TypeError(\"Input does not correspond to encoder encoded data!\")\n",
    "        output = np.nonzero(input_+1)[0][0]/float(self.b)*(self.max-self.min)+self.min\n",
    "        return output\n",
    "    \n",
    "    def decode_ndarray(self,input_):\n",
    "        if input_.shape != (reduce(lambda x, y: x*y, self.ndarray_shape),self.n): \n",
    "            raise ValueError(\"Input dimensions do not match specified encoder dimensions!\")\n",
    "        input_ = input_.reshape(self.ndarray_shape+(self.n,))\n",
    "        output = []\n",
    "        for i in np.ndindex(self.ndarray_shape):\n",
    "            output.append(self.decode(input_[i]))\n",
    "        output = np.array(output).reshape(self.ndarray_shape)\n",
    "        return output\n",
    "    \n",
    "    def set_ndarray_shape(self,shape):\n",
    "        if type(shape) != tuple:\n",
    "            raise TypeError(\"Must provide tuple of array dimensions!\")\n",
    "        self.ndarray_shape = shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_encoder = scalar_sdr(60,21,-0.3,0.3,(6,12))\n",
    "pos_encoder = scalar_sdr(500,21,-100000.0,100000.0,(6,))\n",
    "vel_encoder = scalar_sdr(200,41,-70.0,70.0,(6,))\n",
    "brain_encoder = scalar_sdr(1000,101,0.0,1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = {}\n",
    "for transition in transitions:\n",
    "    encoded_data[transition] = np.array([])\n",
    "    m0 = matrix_encoder.encode_ndarray(matrices[transition[0]])\n",
    "    encoded_data[transition] = np.append(encoded_data[transition], m0.flatten())\n",
    "    m1 = matrix_encoder.encode_ndarray(matrices[transition[1]])\n",
    "    encoded_data[transition] = np.append(encoded_data[transition], m1.flatten())\n",
    "    p = pos_encoder.encode_ndarray(pos[transition[0]])\n",
    "    encoded_data[transition] = np.append(encoded_data[transition], p.flatten())\n",
    "    v = vel_encoder.encode_ndarray(vel[transition[0]])\n",
    "    encoded_data[transition] = np.append(encoded_data[transition], v.flatten())\n",
    "    id_ = brain_encoder.encode(brain_id[transition[1]])\n",
    "    encoded_data[transition] = np.append(encoded_data[transition], id_.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Hopfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
