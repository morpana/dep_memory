{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hopfield Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation for asynchronous Hopfield neural network\n",
    "# Note: memory capacity â‰ƒ 0.14*nodes\n",
    "class Hopfield_Neural_Network:\n",
    "    def __init__(self,nodes,iterations=100,weights=None):\n",
    "        self.nodes = nodes\n",
    "        self.iterations = iterations\n",
    "        try:\n",
    "            if weights == None:\n",
    "                self.weights = np.zeros((nodes,nodes))\n",
    "        except ValueError:\n",
    "            self.weights = weights\n",
    "    \n",
    "    def store(self,input):\n",
    "        dW = np.outer(input.transpose(),input)\n",
    "        np.fill_diagonal(dW,0)\n",
    "        self.weights += dW\n",
    "        \n",
    "    def recall(self,input):\n",
    "        update_sequence = np.random.choice(self.nodes, self.iterations)\n",
    "        for node in update_sequence:\n",
    "            input[node] = np.sign(np.inner(input,self.weights[:,node]))\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnn = Hopfield_Neural_Network(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class matrix_expansion:\n",
    "    \n",
    "    def __init__(self,active_motors):\n",
    "        self.active_motors = active_motors\n",
    "        active_sensors = np.array(active_motors*2)\n",
    "        active_sensors[len(active_motors):] += 14\n",
    "        self.active_sensors = active_sensors\n",
    "        self.shape = ()\n",
    "        \n",
    "    def load_from_file(self,filename):\n",
    "        f = open(filename,\"r\")\n",
    "        matrix = f.read()\n",
    "        f.close()\n",
    "        matrix = re.split(\",NEW_ROW,\",matrix)\n",
    "        matrix.pop()\n",
    "        matrix = np.array([np.array(re.split(\",\", row)).astype(np.float) for row in matrix])\n",
    "        self.shape = matrix.shape\n",
    "        return matrix\n",
    "        \n",
    "    def reduced_matrix(self,matrix):\n",
    "        matrix = matrix[:,self.active_sensors][self.active_motors]\n",
    "        return matrix\n",
    "    \n",
    "    def expanded_matrix(self,reduced_matrix):\n",
    "        matrix = np.zeros(self.shape)\n",
    "        flat = reduced_matrix.flatten()\n",
    "        matrix = np.zeros((14,28))\n",
    "        k = 0\n",
    "        for i in active_motors:\n",
    "            for j in active_sensors:\n",
    "                matrix[i,j] = flat[k]\n",
    "                k += 1\n",
    "        return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_motors = [1,3,4,5,10,12]\n",
    "expander = matrix_expansion(active_motors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Front back\n",
    "filename = \"/home/markus/dep/dep_matrices/front_back.dep\"\n",
    "fb_matrix = expander.load_from_file(filename)\n",
    "fb_reduced = expander.reduced_matrix(fb_matrix)\n",
    "#fb_expanded = expander.expanded_matrix(fb_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Front side\n",
    "filename = \"/home/markus/dep/dep_matrices/front_side.dep\"\n",
    "fs_matrix = expander.load_from_file(filename)\n",
    "fs_reduced = expander.reduced_matrix(fs_matrix)\n",
    "#fs_expanded = expander.expanded_matrix(fs_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side down\n",
    "filename = \"/home/markus/dep/dep_matrices/side_down.dep\"\n",
    "sd_matrix = expander.load_from_file(filename)\n",
    "sd_reduced = expander.reduced_matrix(sd_matrix)\n",
    "#sd_expanded = expander.expanded_matrix(sd_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = {\"fb\": fb_reduced, \"fs\": fs_reduced, \"sd\": sd_reduced, \"zero\": np.zeros(fb_reduced.shape)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors = [\"fb\",\"fs\",\"sd\"]\n",
    "transitions = {(\"fb\",\"fs\"): [], (\"fb\",\"sd\"): [], (\"fs\",\"fb\"): [], (\"fs\",\"sd\"): [], (\"sd\",\"fb\"): [], (\"sd\",\"fs\"): []}\n",
    "transition_muscle_2 = [[-1.5,-1.5,-1.5,-1.5,-1.5,-1.5],[1,1,1,1,1,1]] # [pos,...],[direction,..] -- direction = 1 -> up, direction = 0 -> down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to get positions and velocities for fb, fs and sd at -1.5 going up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb = pickle.load(open(\"/home/markus/dep/dep_data/bases/fb.pickle\",\"rb\"))\n",
    "fs = pickle.load(open(\"/home/markus/dep/dep_data/bases/fs.pickle\",\"rb\"))\n",
    "sd = pickle.load(open(\"/home/markus/dep/dep_data/bases/sd.pickle\", \"rb\"))\n",
    "\n",
    "bases = {\"fb\": fb, \"fs\": fs, \"sd\": sd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtained from plot, time indices that meat transition_muscle_2 condition\n",
    "fb_t = 124\n",
    "fs_t = 126\n",
    "sd_t = 117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos data\n",
    "pos = {\"fb\": fb[0][fb_t][active_motors], \"fs\": fs[0][fs_t][active_motors], \"sd\": sd[0][sd_t][active_motors], \"zero\": np.zeros(np.array(active_motors).shape)}\n",
    "# vel data\n",
    "vel = {\"fb\": fb[1][fb_t][active_motors], \"fs\": fs[1][fs_t][active_motors], \"sd\": sd[1][sd_t][active_motors], \"zero\": np.zeros(np.array(active_motors).shape)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"zero = [0.0,0.25]\"fb\" = [0.25,0.5], \"fs\" = [0.5, 0.75], \"sd\" = [0.75,1.00]\n",
    "brain_id = {\"zero\": 0.125, \"fb\": 0.375, \"fs\": 0.625, \"sd\": 0.875}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTM SDR Scalar Encoder\n",
    "# Input: Scalar\n",
    "# Parameters: n - number of units, w - bits used to represent signal (width), b - buckets (i.e. resolution), \n",
    "#             min - minimum value of input (inclusive), max - maximum input value (inclusive)\n",
    "class scalar_sdr:\n",
    "    \n",
    "    def __init__(self, b, w, min_, max_, shape=0):\n",
    "        if type(b) != int or type(w) != int or type(min_) != float or type(max_) != float:\n",
    "            raise TypeError(\"b - buckets must be int, w - width must be int, min_ must be float and max_ must be float\")\n",
    "        self.b = b # must be int\n",
    "        self.w = w # must be int\n",
    "        self.min = min_ # must be float\n",
    "        self.max = max_ # must be float\n",
    "        self.n = b+w-1 # number of units for encoding\n",
    "        self.ndarray_shape = shape\n",
    "        \n",
    "    def encode(self,input_):\n",
    "        if input_ > self.max or input_ < self.min:\n",
    "            raise ValueError(\"Input outside encoder range!\")\n",
    "        if type(input_) != float:\n",
    "            raise TypeError(\"Input must be float!\")\n",
    "        output = np.zeros(self.n)-1\n",
    "        index = int((input_-self.min)/(self.max-self.min)*self.b)\n",
    "        output[index:index+self.w] = 1\n",
    "        return output\n",
    "    \n",
    "    def encode_ndarray(self,input_):\n",
    "        if input_.shape != self.ndarray_shape:\n",
    "            raise ValueError(\"Input dimensions do not match specified encoder dimensions!\")\n",
    "        output = []\n",
    "        for i in np.nditer(input_, order='K'):\n",
    "            output.append(self.encode(float(i)))\n",
    "        return np.array(output)\n",
    "\n",
    "    def decode(self,input_):\n",
    "        if len(input_) != self.n or len(np.nonzero(input_+1)[0]) != self.w:\n",
    "            raise TypeError(\"Input does not correspond to encoder encoded data!\")\n",
    "        output = np.nonzero(input_+1)[0][0]/float(self.b)*(self.max-self.min)+self.min\n",
    "        return output\n",
    "    \n",
    "    def decode_ndarray(self,input_):\n",
    "        if input_.shape != (reduce(lambda x, y: x*y, self.ndarray_shape),self.n): \n",
    "            raise ValueError(\"Input dimensions do not match specified encoder dimensions!\")\n",
    "        input_ = input_.reshape(self.ndarray_shape+(self.n,))\n",
    "        output = []\n",
    "        for i in np.ndindex(self.ndarray_shape):\n",
    "            output.append(self.decode(input_[i]))\n",
    "        output = np.array(output).reshape(self.ndarray_shape)\n",
    "        return output\n",
    "    \n",
    "    def set_ndarray_shape(self,shape):\n",
    "        if type(shape) != tuple:\n",
    "            raise TypeError(\"Must provide tuple of array dimensions!\")\n",
    "        self.ndarray_shape = shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_encoder = scalar_sdr(60,21,-0.3,0.3,(6,12))\n",
    "pos_encoder = scalar_sdr(500,21,-100000.0,100000.0,(6,))\n",
    "vel_encoder = scalar_sdr(200,41,-70.0,70.0,(6,))\n",
    "brain_encoder = scalar_sdr(1000,101,0.0,1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So what data do we need? What system output do we want? What are the conditions?\n",
    "# Overall input/output vectors (encoded): [state_matrix,matrix,motor_pos,motor_vel,brain_sig]\n",
    "# Note: \n",
    "#      state matrix -- a sensory value from the dep node\n",
    "#      motor_pos and motor_vel -- sensory values from motors\n",
    "#      brain_sig -- single scalar input from brain\n",
    "#      matrix -- the only output of the system, sending a DEP matrix to the dep node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 1: system stationary i.e. zeros (technically transition from zero)\n",
    "# Input: [state_matrix = 0, matrix = 0, motor_pos = 0, motor_vel = 0, brain_id = brain_id]\n",
    "# Desired output: [state_matrix = 0, matrix = matrices[brain_id], motor_pos = 0, motor_vel = 0, brain_sig = brain_id]\n",
    "# Training data = desired output for each brain_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_data = {}\n",
    "for id_ in brain_id:\n",
    "    stationary_data[id_] = np.array([])\n",
    "    \n",
    "    state_matrix = matrix_encoder.encode_ndarray(matrices[\"zero\"]) # Note: this is not changed since it is sensory\n",
    "    stationary_data[id_] = np.append(stationary_data[id_],state_matrix.flatten())\n",
    "    \n",
    "    matrix = matrix_encoder.encode_ndarray(matrices[id_])\n",
    "    stationary_data[id_] = np.append(stationary_data[id_], matrix.flatten())\n",
    "    \n",
    "    motor_pos = pos_encoder.encode_ndarray(pos[\"zero\"])\n",
    "    stationary_data[id_] = np.append(stationary_data[id_],motor_pos.flatten())\n",
    "    \n",
    "    motor_vel = vel_encoder.encode_ndarray(vel[\"zero\"])\n",
    "    stationary_data[id_] = np.append(stationary_data[id_],motor_vel.flatten())\n",
    "    \n",
    "    brain_sig = brain_encoder.encode(brain_id[id_])\n",
    "    stationary_data[id_] = np.append(stationary_data[id_],brain_sig.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 2: transition from one behavior to another based on the input brain_id at the correct motor_pos and motor_vel\n",
    "# Input: [state_matrix = state_matrix, matrix = 0, motor_pos = motor_pos, motor_vel = motor_vel, brain_sig = brain_id]\n",
    "\n",
    "# Desired output: if system state equals the transition point, transition, else don't i.e. requires \"positive\" and \"negative examples\"\n",
    "\n",
    "# if motor_pos ~= pos[brain_id[ and motor_vel ~= vel[brain_id]:\n",
    "#     state_matrix = state_matrix, matrix = matrix[brain_id], motor_pos = motor_pos, motor_vel = motor_vel, brain_sig = brain_id]\n",
    "# else:\n",
    "#    state_matrix = state_matrix, matrix = state_matrix, motor_pos = motor_pos, motor_vel = motor_vel, brain_sig = brain_id]\n",
    "\n",
    "# Training data: single positive example for each transition pair, lots of negatives examples for different motor_pos and motor_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transition point positive examples\n",
    "transitions_positive_data = {}\n",
    "for transition in transitions:\n",
    "    transitions_positive_data[transition] = []\n",
    "    \n",
    "    m0 = matrix_encoder.encode_ndarray(matrices[transition[0]])\n",
    "    transitions_positive_data[transition] = np.append(transitions_positive_data[transition], m0.flatten())\n",
    "    \n",
    "    m1 = matrix_encoder.encode_ndarray(matrices[transition[1]])\n",
    "    transitions_positive_data[transition] = np.append(transitions_positive_data[transition], m1.flatten())\n",
    "    \n",
    "    p = pos_encoder.encode_ndarray(pos[transition[0]])\n",
    "    transitions_positive_data[transition] = np.append(transitions_positive_data[transition], p.flatten())\n",
    "    \n",
    "    v = vel_encoder.encode_ndarray(vel[transition[0]])\n",
    "    transitions_positive_data[transition] = np.append(transitions_positive_data[transition], v.flatten())\n",
    "    \n",
    "    brain_sig = brain_encoder.encode(brain_id[transition[1]])\n",
    "    transitions_positive_data[transition] = np.append(transitions_positive_data[transition], brain_sig.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transition point negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup negative motor_pos and motor_vel data\n",
    "\n",
    "neg_pos = {\"fb\": [], \"fs\": [], \"sd\": []}\n",
    "neg_vel = {\"fb\": [], \"fs\": [], \"sd\": []}\n",
    "\n",
    "steps = [0, 12, 24, 36, 48, 60, 72, 84, 96, 108]\n",
    "\n",
    "for key in bases:\n",
    "    for i in steps:\n",
    "        neg_pos[key].append(bases[key][0][i][active_motors])\n",
    "        neg_vel[key].append(bases[key][1][i][active_motors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain negative examples\n",
    "transitions_negative_data = {}\n",
    "for transition in transitions:\n",
    "    transitions_negative_data[transition] = []\n",
    "    for i in range(len(neg_pos[transition[0]])):\n",
    "        temp = np.array([])\n",
    "        \n",
    "        m0 = matrix_encoder.encode_ndarray(matrices[transition[0]])\n",
    "        temp = np.append(temp, m0.flatten())\n",
    "\n",
    "        m1 = m0\n",
    "        temp = np.append(temp, m1.flatten())\n",
    "\n",
    "        p = pos_encoder.encode_ndarray(neg_pos[transition[0]][i])\n",
    "        temp = np.append(temp, p.flatten())\n",
    "\n",
    "        v = vel_encoder.encode_ndarray(neg_vel[transition[0]][i])\n",
    "        temp = np.append(temp, v.flatten())\n",
    "\n",
    "        brain_sig = brain_encoder.encode(brain_id[transition[1]])\n",
    "        temp = np.append(temp, brain_sig.flatten())\n",
    "        \n",
    "        transitions_negative_data[transition].append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 3: keep situation the same, active high brain signal (technically transitioning from self)\n",
    "maintain = {}\n",
    "for id_ in matrices:\n",
    "    if id_ != \"zero\":\n",
    "        maintain[id_] = []\n",
    "        for i in range(0,len(bases[id_][0]),12):\n",
    "            temp = np.array([])\n",
    "            m0 = matrix_encoder.encode_ndarray(matrices[id_])\n",
    "            temp = np.append(temp, m0.flatten())\n",
    "\n",
    "            m1 = m0\n",
    "            temp = np.append(temp, m1.flatten())\n",
    "\n",
    "            p = pos_encoder.encode_ndarray(bases[key][0][i][active_motors])\n",
    "            temp = np.append(temp, p.flatten())\n",
    "\n",
    "            v = vel_encoder.encode_ndarray(bases[key][1][i][active_motors])\n",
    "            temp = np.append(temp, v.flatten())\n",
    "\n",
    "            braing_sig = brain_encoder.encode(brain_id[id_])\n",
    "            temp = np.append(temp, braing_sig.flatten())\n",
    "            maintain[id_].append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Hopfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "hnn = Hopfield_Neural_Network(17180,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stationary data\n",
    "for item in stationary_data:\n",
    "    hnn.store(stationary_data[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive transitions data\n",
    "for item in transitions_positive_data:\n",
    "    hnn.store(transitions_positive_data[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative transitions\n",
    "for key in transitions_negative_data:\n",
    "    for item in transitions_negative_data[key]:\n",
    "        hnn.store(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maintain status\n",
    "for key in maintain:\n",
    "    for item in maintain[key]:\n",
    "        hnn.store(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
